import tensorflow as tf
import pandas as pd
import numpy as np

# BMI ë°ì´í„° ë¡œë“œí•œ í›„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
csv = pd.read_csv("./resData/bmi.csv")

# ë°ì´í„° ì •ê·œí™” í›„ ê° ì»¬ëŸ¼ì— ì¦‰ì‹œ ì ìš©
csv["height"] = csv["height"] / 200
csv["weight"] = csv["weight"] / 200

# label ì»¬ëŸ¼ì˜ ì²´í˜•ì •ë³´ë¥¼ ì›-í•« ì¸ì½”ë”© í˜•íƒœë¡œ ë³€í™˜(ë”•ì…”ë„ˆë¦¬ë¡œ ì •ì˜)
bclass = {"thin": [1,0,0], "normal": [0,1,0], "fat": [0,0,1]}
# ë³€í™˜í•œ ë°ì´í„°ë¡œ ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„±
csv["label_pat"] = csv["label"].apply(lambda x: np.array(bclass[x])) # Series.apply(func)

print(csv.head())

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
test_csv = csv[15000:20000]
# í…ŒìŠ¤íŠ¸ìš© ì…ë ¥ ë°ì´í„°(ëª¸ë¬´ê²Œ, í‚¤)
test_pat = np.array(test_csv[["weight", "height"]])
# í…ŒìŠ¤íŠ¸ìš© ì •ë‹µ ë ˆì´ë¸”(ì›-í•« ì¸ì½”ë”©)
test_ans = np.array(list(test_csv["label_pat"]))

# ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
'''
ì…ë ¥ë ˆì´ì–´ : í‚¤ì™€ ëª¸ë¬´ê²Œ 2ê°œì˜ ì…ë ¥ê°’ì„ ì‚¬ìš©
ì¶œë ¥ë ˆì´ì–´ : 3ê°œì˜ í´ë˜ìŠ¤(thin, normal, fat) ì‚¬ìš©
    í™œì„±í™”í•¨ìˆ˜ëŠ” softmax ì‚¬ìš©
'''
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(2,)),
    tf.keras.layers.Dense(3, activation='softmax')
])

# ì†ì‹¤í•¨ìˆ˜(í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼)ì™€ ì˜µí‹°ë§ˆì´ì €(SGD: ê²½ì‚¬í•˜ê°•ë²•) ì •ì˜
model.compile(
    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# í•™ìŠµ ë°ì´í„° ì¤€ë¹„
train_pat = np.array(csv[["weight", "height"]])
train_ans = np.array(list(csv["label_pat"]))

import datetime
# TensorBoard ë¡œê·¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
log_dir = "log_dir/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
'''
âœ… ì½œë°±(callback)ì´ë€?
ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë„ì¤‘ íŠ¹ì • ì‹œì ë§ˆë‹¤ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜/ê¸°ëŠ¥
ì˜ˆ:
- ë§¤ epochì´ ëë‚  ë•Œ
- ì¼ì • ì¡°ê±´ì„ ë§Œì¡±í–ˆì„ ë•Œ
- ì¤‘ê°„ ì €ì¥, ë¡œê·¸ ê¸°ë¡, í•™ìŠµ ì¤‘ë‹¨ ë“±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬

ğŸ“¦ TensorFlow ì½œë°± ì¢…ë¥˜
ModelCheckpoint	    ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥
EarlyStopping	    ê³¼ì í•©ë˜ë©´ í•™ìŠµ ìë™ ì¤‘ë‹¨
TensorBoard âœ…	    í•™ìŠµ ë¡œê·¸ë¥¼ ê¸°ë¡í•´ì„œ ì‹œê°í™” ê°€ëŠ¥ => í•™ìŠµ ì¤‘ê°„ì¤‘ê°„ì— loss, accuracy ë“± ê¸°ë¡ì„ ë‚¨ê²¨ì¤Œ
ReduceLROnPlateau	ì„±ëŠ¥ì´ ì•ˆ ì¢‹ì•„ì§€ë©´ í•™ìŠµë¥  ìë™ ì¡°ì ˆ

callbacks=[...]	fit() í•¨ìˆ˜ì—ì„œ ë“±ë¡í•´ì„œ ì‹¤í–‰ë¨
'''
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                                      histogram_freq=1)
'''
log_dir=...
    ë¡œê·¸ë¥¼ ì €ì¥í•  í´ë” ìœ„ì¹˜
histogram_freq=1
    ë§¤ 1 epochë§ˆë‹¤ ê° ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ ë³€í™”, íˆìŠ¤í† ê·¸ë¨ ë“±ë„ ê¸°ë¡í•¨
    â†’ ì´ê±¸ 0ìœ¼ë¡œ í•˜ë©´ ê·¸ëŸ° ì •ë³´ëŠ” ì•ˆ ë‚¨ê¹ë‹ˆë‹¤ (ì†ë„ëŠ” ë¹¨ë¼ì§)
'''

# í•™ìŠµ ì§„í–‰
history = model.fit(
    train_pat, train_ans,
    epochs=35,
    batch_size=100,
    validation_data=(test_pat, test_ans), # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²€ì¦
    verbose=1,
    callbacks=[tensorboard_callback], # TensorBoard ì½œë°± ì¶”ê°€
)

# ìµœì¢… ì •í™•ë„ ì¶œë ¥ : ì†ì‹¤ ê°’ê³¼ ì •í™•ë„ë¥¼ ë°˜í™˜
test_loss, test_acc = model.evaluate(test_pat, test_ans)
print("ì •ë‹µë¥  =", test_acc)

# TensorBoardì— í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡
with tf.summary.create_file_writer(log_dir).as_default() :
    tf.summary.scalar("Test Accuracy", test_acc, step=0)
    tf.summary.scalar("Test Loss", test_loss, step=0)
'''
tf.summary.scalar(name, value, step)
â†’ "ìˆ«ì 1ê°œ(scalar value)ë¥¼ TensorBoard ë¡œê·¸ì— ê¸°ë¡í•˜ëŠ” í•¨ìˆ˜"
name	TensorBoardì— ë³´ì—¬ì§ˆ ì§€í‘œ ì´ë¦„ (ì˜ˆ: "Test Accuracy")
value	ê¸°ë¡í•  ì‹¤ì œ ìˆ«ì ê°’ (ì˜ˆ: 0.94)
step	ì‹œê°„ ì¶•ìœ¼ë¡œ ëª‡ ë²ˆì§¸ stepì¸ì§€ (ë³´í†µ epoch ë²ˆí˜¸)
'''

print(f"TensorBoard write ok : {log_dir}")