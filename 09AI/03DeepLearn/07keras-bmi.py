from tensorflow.keras import Sequential          # ì¸µì„ ìˆœì„œëŒ€ë¡œ ìŒ“ëŠ” ëª¨ë¸
from tensorflow.keras.layers import Dense, Dropout, Activation
from tensorflow.keras.callbacks import EarlyStopping
import pandas as pd, numpy as np
'''
âœ… ì „ì²´ ìš”ì•½ íë¦„
ë°ì´í„° ë¡œë”© ë° ì •ê·œí™”
ë ˆì´ë¸” ì›-í•« ì¸ì½”ë”© (enumerate í™œìš©)
ëª¨ë¸ êµ¬ì„± (layers ë¦¬ìŠ¤íŠ¸ë¡œ)
í•™ìŠµ ì„¤ì • (EarlyStopping í¬í•¨)
í‰ê°€
'''

# BMI ë°ì´í„° ë¡œë“œí•œ í›„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
csv = pd.read_csv("./resData/bmi.csv")

# ë°ì´í„° ì •ê·œí™”
# ëª¸ë¬´ê²Œì™€ í‚¤ ë°ì´í„°ë¥¼ 0~1ì‚¬ì´ì˜ ê°’ì„ ì •ê·œí™”í•œë‹¤.
csv["weight"] = csv["weight"] / 100
csv["height"] = csv["height"] / 200
# ì…ë ¥ë°ì´í„°ë¡œ ì‚¬ìš©. ì •ê·œí™”ëœ ëª¸ë¬´ê²Œì™€ í‚¤ ì»¬ëŸ¼ì„ ì¶”ì¶œ
X = csv[["weight", "height"]]

# ë ˆì´ë¸” ë³€í™˜. ì›-í•« ì¸ì½”ë”© í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±.
bclass = {"thin": [1,0,0], "normal": [0,1,0], "fat": [0,0,1]}
# 2ë§Œê°œì˜ ë ˆì´ë¸” ë°ì´í„°ë¥¼ bclass í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
'''np.empty((20000, 3))ì€ 20000í–‰ Ã— 3ì—´ì§œë¦¬ ë°°ì—´ì„ ë§Œë“œëŠ”ë°,
ê°’ì„ 0ìœ¼ë¡œ ì±„ìš°ì§€ ì•Šê³  "ì“°ë ˆê¸°ê°’"ì´ ë“¤ì–´ ìˆëŠ” ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤.'''
y = np.empty((20000,3))
'''
enumerate()
íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ê°™ì€ ê±¸ ë°˜ë³µí•  ë•Œ, ì¸ë±ìŠ¤(ë²ˆí˜¸)ì™€ ê°’ì„ ë™ì‹œì— êº¼ë‚´ì£¼ëŠ” í•¨ìˆ˜.
=>	(ì¸ë±ìŠ¤, ê°’) í˜•íƒœë¡œ ìˆœíšŒ ê°€ëŠ¥
enumerate(..., start=1)	ì¸ë±ìŠ¤ë¥¼ 1ë¶€í„° ì‹œì‘í•  ìˆ˜ë„ ìˆìŒ

**y[0], y[1], ..., y[19999]**ì— ê° ì›-í•« ë²¡í„°ë¥¼ í•˜ë‚˜ì”© ë„£ëŠ” ê²ƒ
'''
for i, v in enumerate(csv["label"]):
    y[i] = bclass[v]

X_train, y_train = X[1:15001], y[1:15001]
X_test, y_test = X[15001:20001], y[15001:20001]

# ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë ˆì´ì–´ ì •ì˜ í›„ ëª¨ë¸ êµ¬ì¡° ì •ì˜
# ê° ì¸µì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì •ì˜(addí•¨ìˆ˜ ì‚¬ìš©ê³¼ ë™ì¼)
'''
ğŸ” ëª¨ë¸ êµ¬ì„± (ë¦¬ìŠ¤íŠ¸ë¡œ ë ˆì´ì–´ ì •ì˜)
model.add(...) ëŒ€ì‹  ë¦¬ìŠ¤íŠ¸ë¡œ í•œ ë²ˆì— ì •ì˜
Dense(512) = ë…¸ë“œ 512ê°œì¸ ì™„ì „ì—°ê²°ì¸µ
Dropout(0.1) = í•™ìŠµ ì¤‘ 10%ì˜ ë…¸ë“œë¥¼ ë¬´ì‘ìœ„ë¡œ êº¼ì„œ ê³¼ì í•© ë°©ì§€
ë§ˆì§€ë§‰ Activation('softmax') = í™•ë¥ ì²˜ëŸ¼ ì¶œë ¥
'''
layers = [
    Dense(512, input_shape=(2,)),
    Activation('relu'),
    Dropout(0.1),
    Dense(512),
    Activation('softmax')
]
model = Sequential(layers)

# ëª¨ë¸ êµ¬ì¶•. RMSprop ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©. ì†ì‹¤í•¨ìˆ˜ ì ìš©.
model.compile(
    loss = 'categorical_crossentropy',
    optimizer = "rmsprop",
    metrics = ['accuracy']
)

# ë°ì´í„° í›ˆë ¨
hist = model.fit(
    X_train, y_train,
    batch_size=100, # í•œë²ˆì— 100ê°œì”© ë¬¶ì–´ì„œ í•™ìŠµ
    epochs=20, # ìµœëŒ€ 2ê°œë²ˆì˜ ë°˜ë³µí•™ìŠµ
    validation_split=0.1, # í›ˆë ¨ ë°ì´í„° ì¤‘ 10%ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©
    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],
    verbose=1,
)
'''
monitor = 'val_loss' : ê²€ì¦ ì†ì‹¤ê°’(val_loss)ì„ ëª¨ë‹ˆí„°ë§ í•¨.
patience = 2 : ê²€ì¦ ì†ì‹¤ê°’ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ 2ë²ˆ ë” ì§„í–‰í•œ í›„
    ì¡°ê¸°ì¢…ë£Œ(EarlyStopping)
    EarlyStopping	    ê³¼ì í•©ë˜ë©´ í•™ìŠµ ìë™ ì¤‘ë‹¨
ì˜ˆì‹œ)
Epoch 1: val_loss = 0.30  âœ… ì¢‹ì•„ì§
Epoch 2: val_loss = 0.25  âœ… ì¢‹ì•„ì§
Epoch 3: val_loss = 0.27  âŒ ë” ì•ˆ ì¢‹ì•„ì§
Epoch 4: val_loss = 0.28  âŒ ë˜ ì•ˆ ì¢‹ì•„ì§
Epoch 5: (ë©ˆì¶¤!)          ğŸ›‘ patience=2 ì´ˆê³¼
'''

score = model.evaluate(X_test, y_test)
print('loss=', score[0])
print('accuracy=', score[1])